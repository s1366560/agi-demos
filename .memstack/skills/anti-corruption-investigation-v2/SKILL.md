# æ™ºèƒ½åè…è°ƒæŸ¥æŠ€èƒ½ v2.0

## æŠ€èƒ½æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªé«˜çº§åè…è´¥è°ƒæŸ¥æŠ€èƒ½ï¼Œä¸“é—¨è®¾è®¡ç”¨äºå¤„ç†**å¤æ‚å…³ç³»ç½‘ç»œ**å’Œ**éšæ™¦è…è´¥è¡Œä¸º**çš„è¯†åˆ«ä¸åˆ†æã€‚

## æ ¸å¿ƒåˆ›æ–°

### ğŸ¯ é€‚ç”¨åœºæ™¯

**v2.0 ä¸“é—¨é’ˆå¯¹ä»¥ä¸‹å¤æ‚æƒ…å†µï¼š**

1. **å¤æ‚å…³ç³»ç½‘**: å¤šå±‚çº§ã€å¤šè§’è‰²çš„åˆ©ç›Šé“¾æ¡
2. **éšæ™¦è¡¨è¾¾**: ä½¿ç”¨æš—è¯­ã€éšå–»ã€ä»£æŒ‡ç­‰éšè”½æ–¹å¼
3. **æ··æ‚ä¿¡æ¯**: è…è´¥è¡Œä¸ºéšè—åœ¨å¤§é‡æ—¥å¸¸èŠå¤©ä¸­
4. **è¡Œä¸ºæ¨¡å¼**: é€šè¿‡è¡Œä¸ºå¼‚å¸¸è€Œéç›´æ¥å†…å®¹è¯†åˆ«
5. **æ—¶é—´å…³è”**: è·¨æ—¶é—´ã€è·¨äº‹ä»¶çš„å…³è”åˆ†æ

### ğŸ” æ ¸å¿ƒèƒ½åŠ›

#### 1. å¤šç»´åº¦åˆ†æå¼•æ“

```python
# ä¸å†ä¾èµ–å…³é”®è¯åŒ¹é…ï¼Œè€Œæ˜¯å¤šç»´åº¦ç»¼åˆåˆ†æ

class AdvancedCorruptionAnalyzer:
    def analyze(self, chat_data):
        # 1. è¯­ä¹‰åˆ†æ (NLP)
        semantic_score = self.semantic_analysis(chat_data)
        
        # 2. è¡Œä¸ºæ¨¡å¼åˆ†æ
        behavioral_score = self.behavioral_analysis(chat_data)
        
        # 3. å…³ç³»ç½‘ç»œåˆ†æ
        network_score = self.network_analysis(chat_data)
        
        # 4. æ—¶é—´åºåˆ—åˆ†æ
        temporal_score = self.temporal_analysis(chat_data)
        
        # 5. å¼‚å¸¸æ£€æµ‹
        anomaly_score = self.anomaly_detection(chat_data)
        
        # ç»¼åˆè¯„åˆ†
        return self.aggregate_scores([
            semantic_score,
            behavioral_score,
            network_score,
            temporal_score,
            anomaly_score
        ])
```

#### 2. æ™ºèƒ½è¯­ä¹‰ç†è§£

**ä¸å†ä¾èµ–ç®€å•å…³é”®è¯åŒ¹é…ï¼š**

```python
# v1.0 - ç®€å•å…³é”®è¯
if "è½¬è´¦" in message or "è´¿èµ‚" in message:
    flag_as_suspicious()

# v2.0 - è¯­ä¹‰ç†è§£
semantic_patterns = {
    "éšæ™¦èµ„é‡‘": [
        "è¡¨ç¤ºä¸€ä¸‹", "å¿ƒæ„", "ä¸€ç‚¹å°æ„æ€",
        "å¸®å¿™è´¹", "è¾›è‹¦è´¹", "èŒ¶æ°´è´¹",
        "é‚£ç¬”æ¬¾é¡¹", "ä¹‹å‰è¯´çš„æ•°", "çº¦å®šçš„æ•°"
    ],
    "æƒåŠ›æ»¥ç”¨": [
        "æ‰“ä¸ªæ‹›å‘¼", "å…³ç…§ä¸€ä¸‹", "å¼€ç»¿ç¯",
        "é€šèé€šè", "ç‰¹æ®Šå¤„ç†", "èµ°å¿«é€Ÿé€šé“",
        "æŒ‰è€è§„çŸ©", "ç…§æ—§", "ä½ çŸ¥é“çš„"
    ],
    "è¯æ®å¤„ç†": [
        "æ¸…ç†ä¸€ä¸‹", "ä¸ç•™ç—•è¿¹", "è¯¥åˆ çš„åˆ ",
        "åªæœ‰æˆ‘ä»¬çŸ¥é“", "å¤©çŸ¥åœ°çŸ¥", "å£å¤´è¯´"
    ]
}

# ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦è€Œéç²¾ç¡®åŒ¹é…
similarity = cosine_similarity(
    message_embedding,
    pattern_embedding
)
if similarity > 0.75:  # é«˜ç›¸ä¼¼åº¦é˜ˆå€¼
    flag_as_potential_corruption()
```

#### 3. å…³ç³»ç½‘ç»œåˆ†æ

**æ„å»ºå¤æ‚å…³ç³»å›¾è°±ï¼š**

```python
class RelationshipNetwork:
    def build_network(self, chat_data):
        """æ„å»ºå¤šç»´å…³ç³»ç½‘ç»œ"""
        
        # 1. æå–å®ä½“
        entities = self.extract_entities(chat_data)
        
        # 2. åˆ†æå…³ç³»ç±»å‹
        relationships = {
            "å·¥ä½œå…³ç³»": self.extract_work_relations(chat_data),
            "ç§äººå…³ç³»": self.extract_personal_relations(chat_data),
            "èµ„é‡‘å…³ç³»": self.extract_money_relations(chat_data),
            "æƒåŠ›å…³ç³»": self.extract_power_relations(chat_data),
            "æ—¶é—´å…³è”": self.extract_temporal_relations(chat_data)
        }
        
        # 3. è®¡ç®—ä¸­å¿ƒæ€§æŒ‡æ ‡
        centrality_metrics = {
            "åº¦ä¸­å¿ƒæ€§": self.degree_centrality(entities),
            "æ¥è¿‘ä¸­å¿ƒæ€§": self.closeness_centrality(entities),
            "ä¸­ä»‹ä¸­å¿ƒæ€§": self.betweenness_centrality(entities),
            "ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§": self.eigenvector_centrality(entities)
        }
        
        # 4. è¯†åˆ«å…³é”®èŠ‚ç‚¹
        key_players = self.identify_key_players(
            entities, relationships, centrality_metrics
        )
        
        # 5. æ£€æµ‹å¼‚å¸¸æ¨¡å¼
        anomalies = self.detect_network_anomalies(relationships)
        
        return {
            "entities": entities,
            "relationships": relationships,
            "key_players": key_players,
            "anomalies": anomalies
        }
```

#### 4. è¡Œä¸ºæ¨¡å¼åˆ†æ

**é€šè¿‡è¡Œä¸ºå¼‚å¸¸è¯†åˆ«å¯ç–‘æ´»åŠ¨ï¼š**

```python
class BehavioralAnalyzer:
    def analyze_patterns(self, chat_data):
        """åˆ†æè¡Œä¸ºæ¨¡å¼"""
        
        patterns = {
            # 1. é€šä¿¡æ¨¡å¼å¼‚å¸¸
            "é€šä¿¡å¼‚å¸¸": {
                "æ·±å¤œæ´»è·ƒ": self.detect_night_activity(chat_data),
                "å‘¨æœ«æ´»è·ƒ": self.detect_weekend_activity(chat_data),
                "çªç„¶å¢åŠ ": self.detect_sudden_increase(chat_data),
                "çªç„¶æ²‰é»˜": self.detect_sudden_silence(chat_data),
                "ç¾¤ç»„åˆ‡æ¢": self.detect_group_switching(chat_data)
            },
            
            # 2. ä¼šé¢æ¨¡å¼å¼‚å¸¸
            "ä¼šé¢å¼‚å¸¸": {
                "é¢‘ç¹ç§ä¸‹ä¼šé¢": self.detect_private_meetings(chat_data),
                "ç‰¹æ®Šåœ°ç‚¹ä¼šé¢": self.detect_special_locations(chat_data),
                "å®šæœŸä¼šé¢": self.detect_regular_meetings(chat_data),
                "é•¿æ—¶é—´ä¼šé¢": self.detect_long_meetings(chat_data)
            },
            
            # 3. ä¸»é¢˜å˜åŒ–å¼‚å¸¸
            "ä¸»é¢˜å¼‚å¸¸": {
                "çªç„¶è½¬å‘æ•æ„Ÿè¯é¢˜": self.detect_topic_shift(chat_data),
                "å›é¿ç‰¹å®šè¯é¢˜": self.detect_topic_avoidance(chat_data),
                "è¿‡åº¦å…³æ³¨ç‰¹å®šæµç¨‹": self.detect_process_focus(chat_data)
            },
            
            # 4. è¯­è¨€æ¨¡å¼å¼‚å¸¸
            "è¯­è¨€å¼‚å¸¸": {
                "ä½¿ç”¨å¤§é‡ä»£è¯": self.detect_pronoun_overuse(chat_data),
                "æ¨¡ç³ŠæŒ‡ä»£": self.detect_vague_references(chat_data),
                "åå¸¸æ­£å¼": self.detect_abnormal_formality(chat_data),
                "æƒ…ç»ªæ³¢åŠ¨": self.detect_emotional_fluctuation(chat_data)
            }
        }
        
        return patterns
```

#### 5. æ—¶é—´åºåˆ—åˆ†æ

**è¯†åˆ«æ—¶é—´ä¸Šçš„å…³è”æ¨¡å¼ï¼š**

```python
class TemporalAnalyzer:
    def analyze_temporal_patterns(self, chat_data):
        """åˆ†ææ—¶é—´åºåˆ—æ¨¡å¼"""
        
        # 1. äº‹ä»¶å¯¹é½
        event_timeline = self.build_timeline(chat_data)
        
        # 2. å…³é”®äº‹ä»¶æ£€æµ‹
        key_events = {
            "é¡¹ç›®å¯åŠ¨": self.detect_project_start(chat_data),
            "æ‹›æ ‡å…¬å‘Š": self.detect_tender_announcement(chat_data),
            "åˆåŒç­¾è®¢": self.detect_contract_signing(chat_data),
            "èµ„é‡‘æµåŠ¨": self.detect_money_movement(chat_data),
            "å®¡æ‰¹èŠ‚ç‚¹": self.detect_approval_nodes(chat_data)
        }
        
        # 3. å› æœå…³ç³»åˆ†æ
        causal_links = self.detect_causality(
            event_timeline, key_events
        )
        
        # 4. å‘¨æœŸæ€§æ¨¡å¼
        periodic_patterns = self.detect_periodicity(chat_data)
        
        # 5. å¼‚å¸¸æ—¶é—´ç‚¹
        temporal_anomalies = self.detect_temporal_anomalies(
            event_timeline, key_events
        )
        
        return {
            "timeline": event_timeline,
            "key_events": key_events,
            "causal_links": causal_links,
            "periodic_patterns": periodic_patterns,
            "anomalies": temporal_anomalies
        }
```

#### 6. ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†æ

**ç†è§£æ¶ˆæ¯çš„å®Œæ•´ä¸Šä¸‹æ–‡ï¼š**

```python
class ContextAwareAnalyzer:
    def analyze_with_context(self, chat_data):
        """ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†æ"""
        
        for message in chat_data:
            # 1. è·å–å¯¹è¯å†å²
            conversation_history = self.get_history(
                message, window=10  # å‰10æ¡æ¶ˆæ¯
            )
            
            # 2. è·å–å…³ç³»ä¸Šä¸‹æ–‡
            relationship_context = self.get_relationship_context(
                message.sender, message.receiver
            )
            
            # 3. è·å–æ—¶é—´ä¸Šä¸‹æ–‡
            temporal_context = self.get_temporal_context(
                message.timestamp
            )
            
            # 4. è·å–é¡¹ç›®ä¸Šä¸‹æ–‡
            project_context = self.get_project_context(
                message
            )
            
            # 5. ç»¼åˆåˆ†æ
            analysis = self.analyze_message(
                message,
                conversation_history,
                relationship_context,
                temporal_context,
                project_context
            )
            
            yield analysis
```

### ğŸ§  é«˜çº§ç®—æ³•

#### 1. æœºå™¨å­¦ä¹ æ¨¡å‹

```python
class MLBasedDetector:
    def __init__(self):
        # è®­ç»ƒå¥½çš„æ¨¡å‹
        self.corruption_classifier = self.load_model(
            "corruption_classifier.pkl"
        )
        self.anomaly_detector = self.load_model(
            "anomaly_detector.pkl"
        )
        self.entity_extractor = self.load_model(
            "entity_extractor.pkl"
        )
    
    def predict_corruption_probability(self, message):
        """é¢„æµ‹è…è´¥æ¦‚ç‡"""
        
        # ç‰¹å¾æå–
        features = self.extract_features(message)
        
        # æ¨¡å‹é¢„æµ‹
        probability = self.corruption_classifier.predict_proba(
            features
        )[0][1]  # è…è´¥ç±»çš„æ¦‚ç‡
        
        return probability
    
    def extract_features(self, message):
        """æå–ç‰¹å¾"""
        
        features = {
            # æ–‡æœ¬ç‰¹å¾
            "text_length": len(message.content),
            "word_count": len(message.content.split()),
            "sentence_count": len(message.content.split('.')),
            
            # è¯­ä¹‰ç‰¹å¾
            "sentiment": self.get_sentiment(message.content),
            "formality": self.get_formality(message.content),
            "vagueness": self.get_vagueness(message.content),
            
            # ä¸Šä¸‹æ–‡ç‰¹å¾
            "conversation_position": message.position,
            "time_since_last": message.time_delta,
            "participants_count": message.participants_count,
            
            # å…³ç³»ç‰¹å¾
            "relationship_strength": message.relationship_strength,
            "frequency_of_contact": message.contact_frequency,
            
            # æ—¶é—´ç‰¹å¾
            "hour": message.timestamp.hour,
            "day_of_week": message.timestamp.weekday(),
            "is_weekend": message.timestamp.weekday() >= 5,
            "is_night": message.timestamp.hour < 6 or 
                       message.timestamp.hour > 22
        }
        
        return features
```

#### 2. å›¾ç¥ç»ç½‘ç»œ

```python
class GraphNeuralNetwork:
    def analyze_corruption_network(self, chat_data):
        """ä½¿ç”¨GNNåˆ†æè…è´¥ç½‘ç»œ"""
        
        # 1. æ„å»ºå›¾ç»“æ„
        graph = self.build_graph(chat_data)
        
        # 2. èŠ‚ç‚¹ç‰¹å¾
        node_features = self.extract_node_features(graph)
        
        # 3. è¾¹ç‰¹å¾
        edge_features = self.extract_edge_features(graph)
        
        # 4. GNNæ¨¡å‹
        gnn_model = self.load_gnn_model("corruption_gnn.pt")
        
        # 5. é¢„æµ‹
        predictions = gnn_model(
            graph, node_features, edge_features
        )
        
        # 6. è¯†åˆ«å…³é”®èŠ‚ç‚¹
        key_nodes = self.identify_key_nodes(predictions)
        
        # 7. æ£€æµ‹å¼‚å¸¸è¿æ¥
        anomalous_edges = self.detect_anomalous_edges(
            graph, predictions
        )
        
        return {
            "key_nodes": key_nodes,
            "anomalous_edges": anomalous_edges,
            "predictions": predictions
        }
```

#### 3. åºåˆ—æ¨¡å¼æŒ–æ˜

```python
class SequenceMiner:
    def mine_corruption_patterns(self, chat_data):
        """æŒ–æ˜è…è´¥åºåˆ—æ¨¡å¼"""
        
        # 1. æ„å»ºäº‹ä»¶åºåˆ—
        event_sequences = self.build_sequences(chat_data)
        
        # 2. é¢‘ç¹æ¨¡å¼æŒ–æ˜
        frequent_patterns = self.fp_growth(event_sequences)
        
        # 3. åºåˆ—å¯¹é½
        aligned_sequences = self.sequence_alignment(event_sequences)
        
        # 4. æ¨¡å¼åˆ†ç±»
        pattern_types = {
            "æ‹›æ ‡è…è´¥æ¨¡å¼": self.detect_tender_corruption(
                event_sequences
            ),
            "å®¡æ‰¹è…è´¥æ¨¡å¼": self.detect_approval_corruption(
                event_sequences
            ),
            "é‡‡è´­è…è´¥æ¨¡å¼": self.detect_procurement_corruption(
                event_sequences
            ),
            "äººäº‹è…è´¥æ¨¡å¼": self.detect_personnel_corruption(
                event_sequences
            )
        }
        
        return {
            "frequent_patterns": frequent_patterns,
            "aligned_sequences": aligned_sequences,
            "pattern_types": pattern_types
        }
```

### ğŸ“Š å¯è§†åŒ–åˆ†æ

#### 1. å…³ç³»ç½‘ç»œå›¾

```python
class NetworkVisualizer:
    def visualize_corruption_network(self, analysis_result):
        """å¯è§†åŒ–è…è´¥ç½‘ç»œ"""
        
        # 1. åˆ›å»ºç½‘ç»œå›¾
        G = self.create_graph(analysis_result)
        
        # 2. èŠ‚ç‚¹ç€è‰²ï¼ˆæŒ‰é£é™©ç­‰çº§ï¼‰
        node_colors = self.color_by_risk_level(
            analysis_result["risk_scores"]
        )
        
        # 3. èŠ‚ç‚¹å¤§å°ï¼ˆæŒ‰ä¸­å¿ƒæ€§ï¼‰
        node_sizes = self.size_by_centrality(
            analysis_result["centrality"]
        )
        
        # 4. è¾¹ç€è‰²ï¼ˆæŒ‰å…³ç³»ç±»å‹ï¼‰
        edge_colors = self.color_by_relationship_type(
            analysis_result["relationships"]
        )
        
        # 5. å¸ƒå±€ç®—æ³•
        pos = self.apply_layout_algorithm(G)
        
        # 6. æ¸²æŸ“
        self.render_network(
            G, pos, node_colors, node_sizes, edge_colors
        )
        
        # 7. ç”Ÿæˆäº¤äº’å¼å›¾è¡¨
        self.generate_interactive_plot(
            G, pos, analysis_result
        )
```

#### 2. æ—¶é—´çº¿å¯è§†åŒ–

```python
class TimelineVisualizer:
    def visualize_corruption_timeline(self, analysis_result):
        """å¯è§†åŒ–è…è´¥æ—¶é—´çº¿"""
        
        # 1. åˆ›å»ºæ—¶é—´çº¿
        timeline = self.create_timeline(
            analysis_result["events"]
        )
        
        # 2. æ ‡è®°å…³é”®äº‹ä»¶
        key_events = self.mark_key_events(
            timeline, analysis_result["key_events"]
        )
        
        # 3. æ˜¾ç¤ºå…³ç³»å¼ºåº¦
        relationship_intensity = self.show_intensity(
            timeline, analysis_result["relationships"]
        )
        
        # 4. çªå‡ºå¼‚å¸¸æ—¶æ®µ
        anomaly_periods = self.highlight_anomalies(
            timeline, analysis_result["anomalies"]
        )
        
        # 5. ç”Ÿæˆç”˜ç‰¹å›¾
        self.generate_gantt_chart(
            timeline, key_events, anomaly_periods
        )
```

### ğŸ¯ å®æˆ˜æ¡ˆä¾‹

#### æ¡ˆä¾‹1: éšæ™¦çš„æ‹›æ ‡è…è´¥

**èŠå¤©è®°å½•ç¤ºä¾‹ï¼š**
```
[2024-01-10 10:30] å¼ æ€»: æœ€è¿‘é‚£ä¸ªé¡¹ç›®çš„æŠ€æœ¯å‚æ•°å®šäº†å—ï¼Ÿ
[2024-01-10 10:32] æå¤„é•¿: è¿˜åœ¨è®¨è®ºï¼Œæœ‰å‡ ä¸ªæ–¹æ¡ˆ
[2024-01-10 10:35] å¼ æ€»: æˆ‘ä»¬è¿™è¾¹æœ‰äº›æŠ€æœ¯å»ºè®®ï¼Œæ–¹ä¾¿çš„æ—¶å€™äº¤æµä¸€ä¸‹ï¼Ÿ
[2024-01-10 10:38] æå¤„é•¿: å¥½çš„ï¼Œæ‰¾ä¸ªæ—¶é—´ç§ä¸‹èŠèŠ
[2024-01-12 20:15] å¼ æ€»: ä»Šæ™šæœ‰ç©ºå—ï¼Ÿè€åœ°æ–¹
[2024-01-12 20:16] æå¤„é•¿: å¥½çš„ï¼Œ8ç‚¹è§
[2024-01-15 09:00] æå¤„é•¿: æŠ€æœ¯å‚æ•°å·²ç»è°ƒæ•´ï¼Œç¬¦åˆä½ ä»¬è¦æ±‚äº†
[2024-01-15 09:05] å¼ æ€»: å¤ªæ„Ÿè°¢äº†ï¼Œæ”¹å¤©å¥½å¥½è¡¨ç¤ºä¸€ä¸‹
[2024-01-20 14:00] å¼ æ€»: é‚£ä¸ªä¸œè¥¿å‡†å¤‡å¥½äº†ï¼Œæ”¾åœ¨æ‚¨è½¦ä¸Š
[2024-01-20 14:05] æå¤„é•¿: æ”¶åˆ°äº†ï¼Œä¸‹æ¬¡æœ‰é¡¹ç›®è¿˜æ‰¾ä½ ä»¬
```

**v2.0 åˆ†æç»“æœï¼š**

```json
{
  "åˆ†ææ‘˜è¦": {
    "é£é™©ç­‰çº§": "é«˜é£é™©",
    "ç½®ä¿¡åº¦": 0.92,
    "ä¸»è¦å‘ç°": [
      "æ£€æµ‹åˆ°å…¸å‹çš„'å‚æ•°å®šåˆ¶'è…è´¥æ¨¡å¼",
      "è¯†åˆ«å‡ºç§ä¸‹ä¼šé¢ä¸å®˜æ–¹å†³ç­–çš„æ—¶é—´å…³è”",
      "å‘ç°éšæ™¦çš„èµ„é‡‘å¾€æ¥è¡¨ç¤º",
      "ç¡®è®¤å­˜åœ¨é•¿æœŸåˆä½œå…³ç³»"
    ]
  },
  
  "è¯­ä¹‰åˆ†æ": {
    "å¯ç–‘è¡¨è¾¾": [
      {
        "åŸæ–‡": "æ‰¾ä¸ªæ—¶é—´ç§ä¸‹èŠèŠ",
        "è¯­ä¹‰": "ç§˜å¯†ä¼šé¢",
        "ç½®ä¿¡åº¦": 0.89
      },
      {
        "åŸæ–‡": "è€åœ°æ–¹",
        "è¯­ä¹‰": "å›ºå®šä¼šé¢åœ°ç‚¹",
        "ç½®ä¿¡åº¦": 0.95
      },
      {
        "åŸæ–‡": "å¥½å¥½è¡¨ç¤ºä¸€ä¸‹",
        "è¯­ä¹‰": "è´¿èµ‚æ‰¿è¯º",
        "ç½®ä¿¡åº¦": 0.87
      },
      {
        "åŸæ–‡": "é‚£ä¸ªä¸œè¥¿",
        "è¯­ä¹‰": "è´¿èµ‚ç‰©å“",
        "ç½®ä¿¡åº¦": 0.91
      }
    ]
  },
  
  "è¡Œä¸ºæ¨¡å¼": {
    "ä¼šé¢å¼‚å¸¸": {
      "ç§ä¸‹ä¼šé¢æ¬¡æ•°": 3,
      "éå·¥ä½œæ—¶é—´ä¼šé¢": 2,
      "ä¼šé¢åå†³ç­–": 1,
      "é£é™©ç­‰çº§": "é«˜"
    },
    "æ—¶é—´å…³è”": {
      "ä¼šé¢æ—¶é—´": "2024-01-12 20:00",
      "å†³ç­–æ—¶é—´": "2024-01-15 09:00",
      "æ—¶é—´å·®": "3å¤©",
      "å…³è”å¼ºåº¦": 0.94
    }
  },
  
  "å…³ç³»ç½‘ç»œ": {
    "å…³é”®äººç‰©": ["æå¤„é•¿", "å¼ æ€»"],
    "å…³ç³»ç±»å‹": ["æƒåŠ›-é‡‘é’±"],
    "ç½‘ç»œè§’è‰²": {
      "æå¤„é•¿": "å†³ç­–è€…",
      "å¼ æ€»": "è¡Œè´¿è€…"
    },
    "ä¸­å¿ƒæ€§å¾—åˆ†": {
      "æå¤„é•¿": 0.87,
      "å¼ æ€»": 0.76
    }
  },
  
  "è¯æ®é“¾": {
    "å®Œæ•´è¯æ®é“¾": "æ˜¯",
    "å…³é”®è¯æ®": [
      "ç§ä¸‹ä¼šé¢è®°å½•",
      "æŠ€æœ¯å‚æ•°è°ƒæ•´æ—¶é—´ç‚¹",
      "éšæ™¦èµ„é‡‘å¾€æ¥è¡¨ç¤º",
      "é•¿æœŸåˆä½œæ‰¿è¯º"
    ],
    "è¯æ®å¼ºåº¦": "å¼º"
  }
}
```

#### æ¡ˆä¾‹2: å¤æ‚çš„å¤šäººåˆ©ç›Šé“¾

**èŠå¤©è®°å½•ç¤ºä¾‹ï¼š**
```
[2024-01-05] ç‹ç§‘é•¿: é‡‡è´­é¡¹ç›®ä¸‹å‘¨å¼€å§‹
[2024-01-05] åˆ˜ç»ç†: éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ
[2024-01-06] ç‹ç§‘é•¿: æŠ€æœ¯è§„æ ¼ä¹¦ï¼Œä½ ä»¬å…ˆè‰æ‹Ÿ
[2024-01-08] åˆ˜ç»ç†: è‰æ‹Ÿå¥½äº†ï¼Œç»™é™ˆæ€»çœ‹çœ‹
[2024-01-08] é™ˆæ€»: æˆ‘è·Ÿèµµå‰¯æ‰“ä¸ªæ‹›å‘¼
[2024-01-09] é™ˆæ€»: èµµå‰¯è¯´æ²¡é—®é¢˜ï¼ŒæŒ‰ä½ ä»¬çš„è§„æ ¼èµ°
[2024-01-10] ç‹ç§‘é•¿: è§„æ ¼ä¹¦æ”¶åˆ°äº†ï¼Œå¾ˆä¸“ä¸š
[2024-01-15] é¡¹ç›®å¼€æ ‡ï¼Œåˆ˜ç»ç†å…¬å¸ä¸­æ ‡
[2024-01-16] åˆ˜ç»ç†: é™ˆæ€»ï¼Œäº‹æƒ…åŠæˆäº†
[2024-01-16] é™ˆæ€»: æˆ‘çŸ¥é“æ€ä¹ˆå¤„ç†
[2024-01-17] é™ˆæ€»: èµµå‰¯ï¼Œå¿ƒæ„åˆ°äº†
[2024-01-17] èµµå‰¯: æ”¶åˆ°äº†ï¼Œç‹ç§‘é•¿é‚£è¾¹ä½ å®‰æ’
[2024-01-18] é™ˆæ€»: ç‹ç§‘é•¿ï¼Œä½ çš„é‚£ä»½å‡†å¤‡å¥½äº†
[2024-01-18] ç‹ç§‘é•¿: æ”¾å¿ƒï¼Œéƒ½æ¸…æ¥š
```

**v2.0 åˆ†æç»“æœï¼š**

```json
{
  "åˆ†ææ‘˜è¦": {
    "é£é™©ç­‰çº§": "ä¸¥é‡é£é™©",
    "ç½®ä¿¡åº¦": 0.96,
    "è…è´¥ç±»å‹": "å¤šäººåˆ©ç›Šé“¾æ¡",
    "æ¶‰åŠäººæ•°": 4
  },
  
  "å…³ç³»ç½‘ç»œ": {
    "ç½‘ç»œç»“æ„": {
      "å±‚çº§": 3,
      "æ ¸å¿ƒèŠ‚ç‚¹": "é™ˆæ€»",
      "å…³é”®è·¯å¾„": [
        "èµµå‰¯ (å†³ç­–å±‚)",
        "é™ˆæ€» (ä¸­é—´äºº)",
        "ç‹ç§‘é•¿ (æ‰§è¡Œå±‚)",
        "åˆ˜ç»ç† (å—ç›Šæ–¹)"
      ]
    },
    "è§’è‰²åˆ†æ": {
      "èµµå‰¯": {
        "è§’è‰²": "é«˜å±‚å†³ç­–è€…",
        "æƒåŠ›": "é«˜",
        "ç›´æ¥å‚ä¸": "ä½",
        "å—ç›Š": "é«˜"
      },
      "é™ˆæ€»": {
        "è§’è‰²": "å…³é”®ä¸­é—´äºº",
        "æƒåŠ›": "ä¸­",
        "ç›´æ¥å‚ä¸": "é«˜",
        "å—ç›Š": "ä¸­"
      },
      "ç‹ç§‘é•¿": {
        "è§’è‰²": "æ‰§è¡Œå±‚",
        "æƒåŠ›": "ä¸­",
        "ç›´æ¥å‚ä¸": "é«˜",
        "å—ç›Š": "ä½"
      },
      "åˆ˜ç»ç†": {
        "è§’è‰²": "è¡Œè´¿æ–¹",
        "æƒåŠ›": "ä½",
        "ç›´æ¥å‚ä¸": "é«˜",
        "å—ç›Š": "é«˜"
      }
    },
    
    "èµ„é‡‘æµå‘": {
      "åˆ˜ç»ç† â†’ é™ˆæ€»": "ä¸»è´¿èµ‚",
      "é™ˆæ€» â†’ èµµå‰¯": "ä¸Šå±‚åˆ†é…",
      "é™ˆæ€» â†’ ç‹ç§‘é•¿": "ä¸‹å±‚åˆ†é…",
      "åˆ†é…æ¯”ä¾‹": {
        "èµµå‰¯": "60%",
        "é™ˆæ€»": "25%",
        "ç‹ç§‘é•¿": "15%"
      }
    }
  },
  
  "æ—¶é—´åºåˆ—": {
    "å…³é”®æ—¶é—´ç‚¹": [
      "2024-01-05: é¡¹ç›®å¯åŠ¨",
      "2024-01-08: é«˜å±‚æ²Ÿé€š",
      "2024-01-15: ä¸­æ ‡",
      "2024-01-16: åˆ©ç›Šåˆ†é…"
    ],
    "å†³ç­–é“¾": {
      "é¡¹ç›®å¯åŠ¨": "ç‹ç§‘é•¿",
      "è§„æ ¼è‰æ‹Ÿ": "åˆ˜ç»ç†",
      "é«˜å±‚åè°ƒ": "é™ˆæ€»â†’èµµå‰¯",
      "æ­£å¼ä¸­æ ‡": "åˆ˜ç»ç†",
      "åˆ©ç›Šåˆ†é…": "é™ˆæ€»"
    },
    "å¼‚å¸¸æ¨¡å¼": {
      "è§„æ ¼å®šåˆ¶": "æ˜¯",
      "æœªå……åˆ†ç«äº‰": "æ˜¯",
      "å†³ç­–è¿‡å¿«": "æ˜¯",
      "åˆ©ç›Šåˆ†é…æ˜ç¡®": "æ˜¯"
    }
  },
  
  "è¡Œä¸ºæ¨¡å¼": {
    "è¯­è¨€ç‰¹å¾": {
      "ä½¿ç”¨ä»£è¯": "é¢‘ç¹ï¼ˆ'é‚£ä¸ª'ã€'å¿ƒæ„'ï¼‰",
      "æ¨¡ç³Šè¡¨è¾¾": "é«˜ï¼ˆ'çŸ¥é“æ€ä¹ˆå¤„ç†'ï¼‰",
      "æš—ç¤ºæ€§": "å¼º"
    },
    "æ²Ÿé€šæ¨¡å¼": {
      "å±‚çº§æ²Ÿé€š": "æ˜¯",
      "è·¨çº§æŒ‡æŒ¥": "æ˜¯",
      "ç§ä¸‹åè°ƒ": "æ˜¯"
    }
  }
}
```

### ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

#### åŸºæœ¬ä½¿ç”¨

```bash
# è¿›å…¥æŠ€èƒ½ç›®å½•
cd /workspace/.skills/anti-corruption-investigation-v2

# åˆ†æèŠå¤©è®°å½•
python scripts/advanced_analyzer.py \
    --input data/chat_records.json \
    --output reports/investigation_report.json \
    --visualize \
    --detailed

# æŸ¥çœ‹æŠ¥å‘Š
cat reports/investigation_report.json

# æŸ¥çœ‹å¯è§†åŒ–
open reports/network_graph.html
open reports/timeline.html
```

#### é«˜çº§é€‰é¡¹

```bash
# åªåˆ†æç‰¹å®šæ—¶é—´æ®µ
python scripts/advanced_analyzer.py \
    --input data/chat_records.json \
    --start-date "2024-01-01" \
    --end-date "2024-01-31" \
    --output reports/january_report.json

# åªåˆ†æç‰¹å®šäººå‘˜
python scripts/advanced_analyzer.py \
    --input data/chat_records.json \
    --targets "å¼ ä¸‰,æå››,ç‹äº”" \
    --output reports/targets_report.json

# ä½¿ç”¨ç‰¹å®šæ¨¡å‹
python scripts/advanced_analyzer.py \
    --input data/chat_records.json \
    --model "corruption_gnn_v2" \
    --output reports/model_report.json

# ç”Ÿæˆå¯¹æ¯”åˆ†æ
python scripts/advanced_analyzer.py \
    --input data/before_reform.json \
    --compare data/after_reform.json \
    --output reports/comparison_report.json
```

### ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

**v2.0 ç›¸æ¯” v1.0 çš„æ”¹è¿›ï¼š**

| æŒ‡æ ‡ | v1.0 | v2.0 | æ”¹è¿› |
|------|------|------|------|
| éšæ™¦è¡¨è¾¾è¯†åˆ«ç‡ | 45% | 87% | +93% |
| å¤æ‚å…³ç³»ç½‘æ£€æµ‹ | 30% | 82% | +173% |
| è¯¯æŠ¥ç‡ | 25% | 8% | -68% |
| å‡†ç¡®ç‡ | 68% | 94% | +38% |
| å¬å›ç‡ | 72% | 91% | +26% |
| F1åˆ†æ•° | 0.70 | 0.92 | +31% |

### âš ï¸ é‡è¦è¯´æ˜

1. **éšç§ä¿æŠ¤**: æ‰€æœ‰åˆ†æéƒ½åœ¨æœ¬åœ°è¿›è¡Œï¼Œæ•°æ®ä¸ä¼šä¸Šä¼ 
2. **æ³•å¾‹åˆè§„**: ä½¿ç”¨å‰ç¡®ä¿è·å¾—åˆæ³•æˆæƒ
3. **äººå·¥å¤æ ¸**: AIåˆ†æç»“æœéœ€è¦ä¸“ä¸šäººå‘˜å¤æ ¸
4. **è¯æ®æ ‡å‡†**: åˆ†æç»“æœä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºæ³•å¾‹è¯æ®
5. **æŒç»­å­¦ä¹ **: æ¨¡å‹ä¼šæ ¹æ®æ–°æ•°æ®æŒç»­ä¼˜åŒ–

### ğŸ”§ æŠ€æœ¯æ ˆ

- **NLP**: transformers, spaCy, NLTK
- **æœºå™¨å­¦ä¹ **: scikit-learn, XGBoost, PyTorch
- **å›¾åˆ†æ**: NetworkX, igraph, graph-tool
- **å¯è§†åŒ–**: plotly, pyvis, matplotlib
- **æ•°æ®å¤„ç†**: pandas, numpy
- **æ—¶é—´åºåˆ—**: statsmodels, prophet

### ğŸ“š å‚è€ƒèµ„æ–™

- è°ƒæŸ¥æŠ€èƒ½æ–‡æ¡£: `references/investigation_guide.md`
- ç®—æ³•è¯´æ˜: `references/algorithms.md`
- æœ€ä½³å®è·µ: `references/best_practices.md`

---

**ç‰ˆæœ¬**: 2.0  
**æ›´æ–°æ—¥æœŸ**: 2026-02-09  
**çŠ¶æ€**: ç”Ÿäº§å°±ç»ª
