#!/usr/bin/env python3
"""
Anti-Corruption Investigation Tool v5.0

A unified tool for analyzing chat logs to detect corruption patterns,
build relationship networks, and generate human-friendly reports.

Usage:
    python anti_corruption.py analyze <input_file> <output_file> [options]
    python anti_corruption.py relationships <input_file> <output_file> [options]
    python anti_corruption.py full <input_file> <output_dir> [options]

Examples:
    # Basic analysis
    python anti_corruption.py analyze data.jsonl report.json

    # Relationship analysis
    python anti_corruption.py relationships data.jsonl relationships.json

    # Full analysis with all features
    python anti_corruption.py full data.jsonl output/ --batch-size 10000 --workers 8
"""

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Tuple
import re


class MessageParser:
    """Parse chat messages from various formats."""

    @staticmethod
    def parse_jsonl(file_path: str) -> List[Dict[str, Any]]:
        """Parse JSONL format."""
        messages = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    msg = json.loads(line.strip())
                    if MessageParser._validate_message(msg):
                        messages.append(msg)
                except json.JSONDecodeError as e:
                    print(f"Warning: Invalid JSON at line {line_num}: {e}")
        return messages

    @staticmethod
    def parse_txt(file_path: str) -> List[Dict[str, Any]]:
        """Parse TXT format: [timestamp] sender -> receiver: content"""
        messages = []
        pattern = r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]\s*(.+?)\s*->\s*(.+?):\s*(.+)'

        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                match = re.match(pattern, line.strip())
                if match:
                    timestamp, sender, receiver, content = match.groups()
                    messages.append({
                        'timestamp': timestamp,
                        'sender': sender.strip(),
                        'receiver': receiver.strip(),
                        'content': content.strip()
                    })
        return messages

    @staticmethod
    def _validate_message(msg: Dict[str, Any]) -> bool:
        """Validate message has required fields."""
        required = ['timestamp', 'content']
        if not all(field in msg for field in required):
            return False

        # Need either sender, or both sender and receiver
        if 'sender' not in msg:
            return False

        return True


class PatternMatcher:
    """Match corruption patterns using semantic similarity."""

    # Direct patterns (exact matches)
    DIRECT_PATTERNS = {
        'financial_corruption': [
            r'è½¬è´¦|æ±‡æ¬¾|è´¦æˆ·|èµ„é‡‘|é’±æ¬¾|å›æ‰£|è´¿èµ‚|å¥½å¤„è´¹|æ‰‹ç»­è´¹',
            r'é‚£ç¬”é’±|è¿™ç¬”é’±|æ¬¾é¡¹|è´¹ç”¨|åˆ†æˆ|ææˆ|ä½£é‡‘'
        ],
        'power_abuse': [
            r'ç‰¹æ®Šç…§é¡¾|é€šèä¸€ä¸‹|æŒ‰è€è§„çŸ©|å¼€ç»¿ç¯|èµ°åé—¨',
            r'è¿è§„æ“ä½œ|æš—ç®±æ“ä½œ|å†…éƒ¨åè°ƒ|æ‰“æ‹›å‘¼|æ‰¹æ¡å­'
        ],
        'secret_meeting': [
            r'è€åœ°æ–¹|ç§ä¸‹è§é¢|ç§˜å¯†ä¼šé¢|å•ç‹¬èŠèŠ|å½“é¢è¯´',
            r'ä¸è¦å‘Šè¯‰åˆ«äºº|ä¿å¯†|ç§äº‹|ç§ä¸‹|åªæœ‰æˆ‘ä»¬'
        ],
        'collusion': [
            r'ç»Ÿä¸€å£å¾„|å¯¹å¥½ä¾›è¯|ä¸²é€š|å‹¾ç»“|è”æ‰‹|åˆä½œ',
            r'åˆ é™¤è®°å½•|æ¸…ç†èŠå¤©|é”€æ¯è¯æ®|ä¸ç•™ç—•è¿¹'
        ]
    }

    # Semantic patterns (éšæ™¦è¡¨è¾¾)
    SEMANTIC_PATTERNS = {
        'financial_corruption': [
            'ä¸œè¥¿å‡†å¤‡å¥½äº†å—', 'é‚£ä¸ªä¸œè¥¿', 'äº‹æƒ…åŠå¾—æ€ä¹ˆæ ·äº†',
            'è¡¨ç¤ºä¸€ä¸‹', 'å¿ƒæ„', 'æ„æ€ä¸€ä¸‹', 'æ„Ÿè°¢è´¹'
        ],
        'power_abuse': [
            'å¸®å¿™çœ‹çœ‹', 'å…³ç…§ä¸€ä¸‹', 'ç…§é¡¾ä¸€ä¸‹', 'å¸®å¿™å¤„ç†',
            'ç‰¹äº‹ç‰¹åŠ', 'æŒ‰æƒ¯ä¾‹', 'è€è§„çŸ©', 'éƒ½çŸ¥é“çš„'
        ],
        'secret_meeting': [
            'è§é¢èŠ', 'å½“é¢è°ˆ', 'å‡ºæ¥åå', 'ä¸€èµ·åƒé¥­',
            'è€åœ°æ–¹è§', 'ç§ä¸‹è¯´', 'ä¸æ–¹ä¾¿åœ¨è¿™é‡Œè¯´'
        ],
        'collusion': [
            'ä¿æŒä¸€è‡´', 'è¿™ä¹ˆè¯´', 'ç»Ÿä¸€è¯´æ³•', 'å£å¾„ä¸€è‡´',
            'åˆ é™¤å§', 'æ¸…ç†ä¸€ä¸‹', 'åˆ«ç•™è®°å½•', 'æ’¤å›æ¶ˆæ¯'
        ]
    }

    @classmethod
    def match_patterns(cls, content: str) -> List[str]:
        """Match content against corruption patterns."""
        matched = []

        # Direct pattern matching
        for category, patterns in cls.DIRECT_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, content):
                    matched.append(category)
                    break

        # Semantic pattern matching
        for category, patterns in cls.SEMANTIC_PATTERNS.items():
            if category in matched:
                continue  # Already matched by direct pattern
            for pattern in patterns:
                if pattern in content:
                    matched.append(category)
                    break

        return matched


class TimeAnalyzer:
    """Analyze time-based patterns."""

    @staticmethod
    def is_late_night(timestamp: str) -> bool:
        """Check if message is sent during late night (22:00-06:00)."""
        try:
            # Parse timestamp
            if 'T' in timestamp:
                time_part = timestamp.split('T')[1][:5]
            else:
                time_part = timestamp.split()[1][:5]

            hour = int(time_part.split(':')[0])
            return hour >= 22 or hour < 6
        except (ValueError, IndexError):
            return False

    @staticmethod
    def is_weekend(timestamp: str) -> bool:
        """Check if message is sent during weekend."""
        try:
            if 'T' in timestamp:
                date_part = timestamp.split('T')[0]
            else:
                date_part = timestamp.split()[0]

            dt = datetime.strptime(date_part, '%Y-%m-%d')
            return dt.weekday() >= 5  # 5=Saturday, 6=Sunday
        except (ValueError, IndexError):
            return False


class ChatAnalyzer:
    """Analyze chat messages for corruption patterns."""

    def __init__(self, messages: List[Dict[str, Any]]):
        self.messages = messages

    def analyze(self) -> Dict[str, Any]:
        """Perform comprehensive analysis."""
        suspicious_messages = []
        pattern_counts = {key: 0 for key in PatternMatcher.DIRECT_PATTERNS.keys()}
        time_anomalies = {'late_night': 0, 'weekend': 0}

        for msg in self.messages:
            content = msg.get('content', '')
            timestamp = msg.get('timestamp', '')

            # Match patterns
            matched = PatternMatcher.match_patterns(content)
            if matched:
                suspicious_msg = {
                    'timestamp': timestamp,
                    'sender': msg.get('sender', 'Unknown'),
                    'receiver': msg.get('receiver', 'Unknown'),
                    'content': content,
                    'patterns': matched
                }

                # Add time anomalies
                if TimeAnalyzer.is_late_night(timestamp):
                    suspicious_msg['time_anomaly'] = 'late_night'
                    time_anomalies['late_night'] += 1
                elif TimeAnalyzer.is_weekend(timestamp):
                    suspicious_msg['time_anomaly'] = 'weekend'
                    time_anomalies['weekend'] += 1

                suspicious_messages.append(suspicious_msg)

                # Count patterns
                for pattern in matched:
                    if pattern in pattern_counts:
                        pattern_counts[pattern] += 1

        # Calculate risk score
        risk_score = self._calculate_risk(suspicious_messages, pattern_counts, time_anomalies)

        # Identify key players
        key_players = self._identify_key_players(suspicious_messages)

        return {
            'total_messages': len(self.messages),
            'suspicious_count': len(suspicious_messages),
            'suspicious_rate': len(suspicious_messages) / len(self.messages) if self.messages else 0,
            'pattern_counts': pattern_counts,
            'time_anomalies': time_anomalies,
            'risk_score': risk_score,
            'risk_level': self._get_risk_level(risk_score),
            'suspicious_messages': suspicious_messages[:100],  # Limit output
            'key_players': key_players
        }

    def _calculate_risk(self, suspicious: List[Dict], patterns: Dict, times: Dict) -> float:
        """Calculate overall risk score (0-10)."""
        if not self.messages:
            return 0.0

        # Base score from suspicious rate
        suspicious_rate = len(suspicious) / len(self.messages)
        score = suspicious_rate * 10

        # Bonus for pattern diversity
        pattern_types = sum(1 for v in patterns.values() if v > 0)
        score += pattern_types * 0.5

        # Bonus for time anomalies
        time_score = (times['late_night'] + times['weekend']) / len(self.messages) * 10
        score += time_score * 0.3

        return min(score, 10.0)

    def _get_risk_level(self, score: float) -> str:
        """Convert risk score to level."""
        if score >= 6:
            return f"ğŸ”´ é«˜é£é™© ({score:.1f}/10)"
        elif score >= 3:
            return f"ğŸŸ  ä¸­é£é™© ({score:.1f}/10)"
        else:
            return f"ğŸŸ¢ ä½é£é™© ({score:.1f}/10)"

    def _identify_key_players(self, suspicious: List[Dict]) -> List[Dict]:
        """Identify key players based on involvement."""
        player_counts = {}

        for msg in suspicious:
            sender = msg['sender']
            player_counts[sender] = player_counts.get(sender, 0) + 1

        # Sort by count
        sorted_players = sorted(player_counts.items(), key=lambda x: x[1], reverse=True)

        return [
            {'name': name, 'suspicious_count': count}
            for name, count in sorted_players[:10]
        ]


class RelationshipAnalyzer:
    """Analyze relationships between individuals."""

    def __init__(self, messages: List[Dict[str, Any]]):
        self.messages = messages

    def analyze(self) -> Dict[str, Any]:
        """Analyze relationships and build network."""
        relationships = {}
        message_counts = {}

        # Build relationships
        for msg in self.messages:
            sender = msg.get('sender', 'Unknown')
            receiver = msg.get('receiver', 'Unknown')

            if sender == 'Unknown' or receiver == 'Unknown':
                continue

            # Create unique key
            key = tuple(sorted([sender, receiver]))

            if key not in relationships:
                relationships[key] = {
                    'person_a': sender,
                    'person_b': receiver,
                    'message_count': 0,
                    'patterns': set(),
                    'evidence': []
                }

            relationships[key]['message_count'] += 1
            message_counts[key] = message_counts.get(key, 0) + 1

            # Check for patterns
            content = msg.get('content', '')
            matched = PatternMatcher.match_patterns(content)

            for pattern in matched:
                relationships[key]['patterns'].add(pattern)

            # Add evidence
            if matched:
                relationships[key]['evidence'].append({
                    'timestamp': msg.get('timestamp', ''),
                    'sender': sender,
                    'receiver': receiver,
                    'content': content,
                    'patterns': matched
                })

        # Convert to list and calculate strength
        relationship_list = []
        for rel in relationships.values():
            rel['patterns'] = list(rel['patterns'])

            # Calculate relationship strength
            max_count = max(message_counts.values()) if message_counts else 1
            rel['strength'] = rel['message_count'] / max_count

            # Determine relationship type
            rel['relationship_type'] = self._get_relationship_type(rel['patterns'])

            # Assess risk
            rel['risk_level'] = self._assess_risk(rel)

            relationship_list.append(rel)

        # Sort by message count
        relationship_list.sort(key=lambda x: x['message_count'], reverse=True)

        return {
            'total_relationships': len(relationship_list),
            'top_relationships': relationship_list[:50],  # Top 50
            'statistics': self._calculate_statistics(relationship_list)
        }

    def _get_relationship_type(self, patterns: List[str]) -> List[str]:
        """Map patterns to relationship types."""
        type_map = {
            'financial_corruption': 'èµ„é‡‘å¾€æ¥',
            'power_abuse': 'æƒåŠ›æ»¥ç”¨',
            'secret_meeting': 'ç§˜å¯†ä¼šé¢',
            'collusion': 'ä¸²é€šå‹¾ç»“'
        }

        types = []
        for pattern in patterns:
            if pattern in type_map:
                types.append(type_map[pattern])

        # Add frequent contact if high message count
        if not types:
            types.append('é¢‘ç¹è”ç³»')

        return types

    def _assess_risk(self, rel: Dict) -> str:
        """Assess risk level of relationship."""
        score = 0

        # Pattern-based score
        pattern_score = len(rel['patterns']) * 2
        score += pattern_score

        # Strength-based score
        if rel['strength'] > 0.8:
            score += 3
        elif rel['strength'] > 0.5:
            score += 2
        elif rel['strength'] > 0.3:
            score += 1

        # Evidence count
        if len(rel['evidence']) > 10:
            score += 2
        elif len(rel['evidence']) > 5:
            score += 1

        if score >= 7:
            return f"ğŸ”´ é«˜é£é™© - éœ€è¦é‡ç‚¹å…³æ³¨ ({score}/10)"
        elif score >= 4:
            return f"ğŸŸ  ä¸­é£é™© - éœ€è¦å…³æ³¨ ({score}/10)"
        else:
            return f"ğŸŸ¢ ä½é£é™© - æ­£å¸¸ç›‘æ§ ({score}/10)"

    def _calculate_statistics(self, relationships: List[Dict]) -> Dict:
        """Calculate network statistics."""
        if not relationships:
            return {}

        return {
            'avg_message_count': sum(r['message_count'] for r in relationships) / len(relationships),
            'max_message_count': max(r['message_count'] for r in relationships),
            'high_risk_count': sum(1 for r in relationships if 'é«˜é£é™©' in r['risk_level']),
            'medium_risk_count': sum(1 for r in relationships if 'ä¸­é£é™©' in r['risk_level']),
            'low_risk_count': sum(1 for r in relationships if 'ä½é£é™©' in r['risk_level'])
        }


class ReportGenerator:
    """Generate human-friendly reports."""

    @staticmethod
    def generate_relationship_report(relationships: Dict[str, Any]) -> str:
        """Generate human-readable relationship report."""
        lines = []
        lines.append("=" * 80)
        lines.append("åè…è´¥è°ƒæŸ¥ - å…³ç³»ç½‘ç»œåˆ†ææŠ¥å‘Š")
        lines.append("=" * 80)
        lines.append("")

        # Summary
        stats = relationships.get('statistics', {})
        lines.append("ğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
        lines.append(f"  â€¢ æ€»å…³ç³»æ•°: {relationships['total_relationships']}")
        if stats:
            lines.append(f"  â€¢ å¹³å‡æ¶ˆæ¯æ•°: {stats['avg_message_count']:.1f}")
            lines.append(f"  â€¢ æœ€å¤§æ¶ˆæ¯æ•°: {stats['max_message_count']}")
            lines.append(f"  â€¢ é«˜é£é™©å…³ç³»: {stats['high_risk_count']}")
            lines.append(f"  â€¢ ä¸­é£é™©å…³ç³»: {stats['medium_risk_count']}")
            lines.append(f"  â€¢ ä½é£é™©å…³ç³»: {stats['low_risk_count']}")
        lines.append("")

        # Top relationships
        lines.append("ğŸ¯ Top å…³é”®å…³ç³»:")
        lines.append("")

        for i, rel in enumerate(relationships['top_relationships'][:20], 1):
            lines.append(f"{i}. {rel['person_a']} â†” {rel['person_b']}")
            lines.append(f"   å…³ç³»ç±»å‹: {', '.join(rel['relationship_type'])}")
            lines.append(f"   å…³ç³»å¼ºåº¦: {ReportGenerator._get_strength_emoji(rel['strength'])} {rel['strength']:.2f}")
            lines.append(f"   è”ç³»æ¬¡æ•°: {rel['message_count']}æ¬¡")
            lines.append(f"   é£é™©ç­‰çº§: {rel['risk_level']}")

            # Show evidence
            if rel['evidence']:
                lines.append(f"   å…³é”®è¯æ®:")
                for evidence in rel['evidence'][:3]:
                    lines.append(f"   â€¢ [{evidence['timestamp']}] {evidence['sender']} -> {evidence['receiver']}")
                    lines.append(f"     {evidence['content'][:80]}...")

            lines.append("")

        return "\n".join(lines)

    @staticmethod
    def _get_strength_emoji(strength: float) -> str:
        """Get emoji for relationship strength."""
        if strength >= 0.8:
            return "ğŸ”´ éå¸¸å¼º"
        elif strength >= 0.5:
            return "ğŸŸ  å¼º"
        elif strength >= 0.3:
            return "ğŸŸ¡ ä¸­ç­‰"
        else:
            return "ğŸŸ¢ å¼±"


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Anti-Corruption Investigation Tool v5.0',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    subparsers = parser.add_subparsers(dest='command', help='Command to execute')

    # Analyze command
    analyze_parser = subparsers.add_parser('analyze', help='Analyze chat messages for corruption patterns')
    analyze_parser.add_argument('input_file', help='Input file (JSONL or TXT)')
    analyze_parser.add_argument('output_file', help='Output JSON file')

    # Relationships command
    rel_parser = subparsers.add_parser('relationships', help='Analyze relationships between individuals')
    rel_parser.add_argument('input_file', help='Input file (JSONL or TXT)')
    rel_parser.add_argument('output_file', help='Output JSON file')
    rel_parser.add_argument('--text-report', help='Also generate text report')

    # Full command
    full_parser = subparsers.add_parser('full', help='Run full analysis')
    full_parser.add_argument('input_file', help='Input file (JSONL or TXT)')
    full_parser.add_argument('output_dir', help='Output directory')
    full_parser.add_argument('--batch-size', type=int, default=10000, help='Batch size for processing')
    full_parser.add_argument('--workers', type=int, default=4, help='Number of workers')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    # Load messages
    print(f"ğŸ” Loading messages from {args.input_file}...")
    input_path = Path(args.input_file)

    if not input_path.exists():
        print(f"âŒ Error: File not found: {args.input_file}")
        sys.exit(1)

    # Parse based on extension
    if input_path.suffix == '.jsonl':
        messages = MessageParser.parse_jsonl(str(input_path))
    elif input_path.suffix == '.txt':
        messages = MessageParser.parse_txt(str(input_path))
    else:
        # Try JSONL first
        try:
            messages = MessageParser.parse_jsonl(str(input_path))
        except:
            messages = MessageParser.parse_txt(str(input_path))

    print(f"âœ… Loaded {len(messages)} messages")

    # Execute command
    if args.command == 'analyze':
        print("ğŸ”¬ Analyzing messages...")
        analyzer = ChatAnalyzer(messages)
        results = analyzer.analyze()

        print(f"ğŸ“Š Found {results['suspicious_count']} suspicious messages")
        print(f"ğŸ¯ Risk Level: {results['risk_level']}")

        # Save results
        with open(args.output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"âœ… Results saved to {args.output_file}")

    elif args.command == 'relationships':
        print("ğŸ•¸ï¸ Analyzing relationships...")
        analyzer = RelationshipAnalyzer(messages)
        results = analyzer.analyze()

        print(f"ğŸ“Š Found {results['total_relationships']} relationships")

        # Save JSON results
        with open(args.output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"âœ… Results saved to {args.output_file}")

        # Generate text report if requested
        if args.text_report:
            print("ğŸ“ Generating text report...")
            report = ReportGenerator.generate_relationship_report(results)

            with open(args.text_report, 'w', encoding='utf-8') as f:
                f.write(report)

            print(f"âœ… Text report saved to {args.text_report}")

    elif args.command == 'full':
        print("ğŸš€ Running full analysis...")
        output_dir = Path(args.output_dir)
        output_dir.mkdir(exist_ok=True)

        # Run both analyses
        print("ğŸ”¬ Analyzing messages...")
        chat_analyzer = ChatAnalyzer(messages)
        chat_results = chat_analyzer.analyze()

        chat_output = output_dir / 'chat_analysis.json'
        with open(chat_output, 'w', encoding='utf-8') as f:
            json.dump(chat_results, f, ensure_ascii=False, indent=2)
        print(f"âœ… Chat analysis saved to {chat_output}")

        print("ğŸ•¸ï¸ Analyzing relationships...")
        rel_analyzer = RelationshipAnalyzer(messages)
        rel_results = rel_analyzer.analyze()

        rel_output = output_dir / 'relationships.json'
        with open(rel_output, 'w', encoding='utf-8') as f:
            json.dump(rel_results, f, ensure_ascii=False, indent=2)
        print(f"âœ… Relationships saved to {rel_output}")

        # Generate text report
        print("ğŸ“ Generating text report...")
        report = ReportGenerator.generate_relationship_report(rel_results)

        report_output = output_dir / 'report.txt'
        with open(report_output, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ… Text report saved to {report_output}")

    print("\nğŸ‰ Analysis complete!")


if __name__ == '__main__':
    main()
