#!/usr/bin/env python3
"""Refactor process() method in processor.py to reduce branches/statements.

Extracts helper methods:
- _check_abort_and_limits() -> AgentErrorEvent | None
- _classify_step_event() -> tuple[ProcessorResult, bool]
- _evaluate_no_tool_result() -> AsyncIterator (sets _last_process_result)
- _append_tool_results_to_messages() -> None
- _emit_completion_events() -> AsyncIterator
- _build_trace_url() -> str | None
"""

import sys

PROCESSOR_PATH = "src/infrastructure/agent/processor/processor.py"


def main():
    with open(PROCESSOR_PATH, "r") as f:
        content = f.read()
    lines = content.split("\n")

    # Find the process() method start and _extract_user_query start
    start_idx = None
    end_idx = None
    for i, line in enumerate(lines):
        if "async def process(" in line and i + 1 < len(lines) and "self," in lines[i + 1]:
            start_idx = i
        if start_idx is not None and i > start_idx and "def _extract_user_query(" in line:
            end_idx = i
            break

    if start_idx is None or end_idx is None:
        print(f"ERROR: Could not find process() boundaries. start={start_idx}, end={end_idx}")
        sys.exit(1)

    print(f"Found process() at lines {start_idx + 1}-{end_idx} (0-indexed)")

    replacement = [
        "    async def process(",
        "        self,",
        "        session_id: str,",
        "        messages: list[dict[str, Any]],",
        "        abort_signal: asyncio.Event | None = None,",
        "        langfuse_context: dict[str, Any] | None = None,",
        "    ) -> AsyncIterator[ProcessorEvent]:",
        '        """',
        "        Process a conversation turn.",
        "",
        "        Runs the ReAct loop:",
        "        1. Call LLM with messages",
        "        2. Process response (text, reasoning, tool calls)",
        "        3. Execute tool calls if any",
        "        4. Continue until complete or blocked",
        "",
        "        Args:",
        "            session_id: Session identifier",
        "            messages: Conversation messages in OpenAI format",
        "            abort_signal: Optional abort signal",
        "            langfuse_context: Optional context for Langfuse tracing containing:",
        "                - conversation_id: Unique conversation identifier",
        "                - user_id: User identifier",
        "                - tenant_id: Tenant identifier for multi-tenant isolation",
        "                - project_id: Project identifier",
        "                - extra: Additional metadata dict",
        "",
        "        Yields:",
        "            AgentDomainEvent objects and dict passthrough events for real-time streaming",
        '        """',
        "        self._abort_event = abort_signal or asyncio.Event()",
        "        self._step_count = 0",
        "        self._no_progress_steps = 0",
        "        self._langfuse_context = langfuse_context  # Store for use in _process_step",
        "",
        "        # Emit start event",
        "        yield AgentStartEvent()",
        "        self._state = ProcessorState.THINKING",
        "",
        "        try:",
        "            result = ProcessorResult.CONTINUE",
        "",
        "            while result == ProcessorResult.CONTINUE:",
        "                abort_event = self._check_abort_and_limits()",
        "                if abort_event is not None:",
        "                    yield abort_event",
        "                    self._state = ProcessorState.ERROR",
        "                    return",
        "",
        "                # Process one step and classify events",
        "                had_tool_calls = False",
        "                async for event in self._process_step(session_id, messages):",
        "                    yield event",
        "                    result, had_tool_calls = self._classify_step_event(",
        "                        event, result, had_tool_calls",
        "                    )",
        "                    if result in (ProcessorResult.STOP, ProcessorResult.COMPACT):",
        "                        break",
        "",
        "                # Evaluate goal if no tool calls and still continuing",
        "                if result == ProcessorResult.CONTINUE:",
        "                    if had_tool_calls:",
        "                        self._no_progress_steps = 0",
        "                    else:",
        "                        async for evt in self._evaluate_no_tool_result(",
        "                            session_id, messages",
        "                        ):",
        "                            yield evt",
        "                        result = self._last_process_result",
        "",
        "                # Append tool results to messages for next iteration",
        "                if result == ProcessorResult.CONTINUE:",
        "                    self._append_tool_results_to_messages(messages)",
        "",
        "            # Emit completion events",
        "            async for event in self._emit_completion_events(",
        "                result, session_id, messages",
        "            ):",
        "                yield event",
        "",
        "        except Exception as e:",
        '            logger.error(f"Processor error: {e}", exc_info=True)',
        "            yield AgentErrorEvent(message=str(e), code=type(e).__name__)",
        "            self._state = ProcessorState.ERROR",
        "",
        "    def _check_abort_and_limits(self) -> AgentErrorEvent | None:",
        '        """Check abort signal and step limits. Returns error event or None."""',
        "        if self._abort_event.is_set():",
        '            return AgentErrorEvent(message="Processing aborted", code="ABORTED")',
        "        self._step_count += 1",
        "        if self._step_count > self.config.max_steps:",
        "            return AgentErrorEvent(",
        '                message=f"Maximum steps ({self.config.max_steps}) exceeded",',
        '                code="MAX_STEPS_EXCEEDED",',
        "            )",
        "        return None",
        "",
        "    def _classify_step_event(",
        "        self,",
        "        event: ProcessorEvent,",
        "        current_result: ProcessorResult,",
        "        had_tool_calls: bool,",
        "    ) -> tuple[ProcessorResult, bool]:",
        '        """Classify a step event and update loop control state."""',
        "        event_type_raw = (",
        '            event.get("type")',
        "            if isinstance(event, dict)",
        '            else getattr(event, "event_type", None)',
        "        )",
        "        event_type = (",
        "            event_type_raw.value",
        "            if isinstance(event_type_raw, AgentEventType)",
        "            else event_type_raw",
        "        )",
        "        if event_type == AgentEventType.ERROR.value:",
        "            return ProcessorResult.STOP, had_tool_calls",
        "        if event_type == AgentEventType.ACT.value:",
        "            return current_result, True",
        "        if event_type == AgentEventType.COMPACT_NEEDED.value:",
        "            return ProcessorResult.COMPACT, had_tool_calls",
        "        return current_result, had_tool_calls",
        "",
        "    async def _evaluate_no_tool_result(",
        "        self, session_id: str, messages: list[dict[str, Any]]",
        "    ) -> AsyncIterator[ProcessorEvent]:",
        '        """Evaluate goal completion when no tools were called.',
        "",
        "        Sets self._last_process_result for the caller to read.",
        '        """',
        "        goal_check = await self._evaluate_goal_completion(session_id, messages)",
        "        if goal_check.achieved:",
        "            self._no_progress_steps = 0",
        '            yield AgentStatusEvent(status=f"goal_achieved:{goal_check.source}")',
        "            self._last_process_result = ProcessorResult.COMPLETE",
        "            return",
        "",
        "        if self._is_conversational_response():",
        "            # Text-only response without tool calls and without an",
        "            # explicit goal_achieved=false signal -- treat as a",
        "            # deliberate conversational reply.",
        "            self._no_progress_steps = 0",
        '            yield AgentStatusEvent(status="goal_achieved:conversational_response")',
        "            self._last_process_result = ProcessorResult.COMPLETE",
        "            return",
        "",
        "        if goal_check.should_stop:",
        "            yield AgentErrorEvent(",
        '                message=goal_check.reason or "Goal cannot be completed",',
        '                code="GOAL_NOT_ACHIEVED",',
        "            )",
        "            self._state = ProcessorState.ERROR",
        "            self._last_process_result = ProcessorResult.STOP",
        "            return",
        "",
        "        # No progress -- check if we should give up",
        "        self._no_progress_steps += 1",
        '        yield AgentStatusEvent(status=f"goal_pending:{goal_check.source}")',
        "        if self._no_progress_steps > 1:",
        '            yield AgentStatusEvent(status="planning_recheck")',
        "        if self._no_progress_steps >= self.config.max_no_progress_steps:",
        "            yield AgentErrorEvent(",
        "                message=(",
        '                    "Goal not achieved after "',
        '                    f"{self._no_progress_steps} no-progress turns. "',
        "                    f\"{goal_check.reason or 'Replan required.'}\"",
        "                ),",
        '                code="GOAL_NOT_ACHIEVED",',
        "            )",
        "            self._state = ProcessorState.ERROR",
        "            self._last_process_result = ProcessorResult.STOP",
        "            return",
        "        self._last_process_result = ProcessorResult.CONTINUE",
        "",
        "    def _append_tool_results_to_messages(",
        "        self, messages: list[dict[str, Any]]",
        "    ) -> None:",
        '        """Append current message and tool results to the message list."""',
        "        if not self._current_message:",
        "            return",
        "        messages.append(self._current_message.to_llm_format())",
        "        for part in self._current_message.get_tool_parts():",
        "            if part.status == ToolState.COMPLETED:",
        "                messages.append(",
        "                    {",
        '                        "role": "tool",',
        '                        "tool_call_id": part.call_id,',
        '                        "content": part.output or "",',
        "                    }",
        "                )",
        "            elif part.status == ToolState.ERROR:",
        "                messages.append(",
        "                    {",
        '                        "role": "tool",',
        '                        "tool_call_id": part.call_id,',
        '                        "content": f"Error: {part.error}",',
        "                    }",
        "                )",
        "",
        "    async def _emit_completion_events(",
        "        self,",
        "        result: ProcessorResult,",
        "        session_id: str,",
        "        messages: list[dict[str, Any]],",
        "    ) -> AsyncIterator[ProcessorEvent]:",
        '        """Emit final completion or compact events."""',
        "        if result == ProcessorResult.COMPLETE:",
        "            suggestions_event = await self._generate_suggestions(messages)",
        "            if suggestions_event:",
        "                yield suggestions_event",
        "            trace_url = self._build_trace_url(session_id)",
        "            yield AgentCompleteEvent(trace_url=trace_url)",
        "            self._state = ProcessorState.COMPLETED",
        "        elif result == ProcessorResult.COMPACT:",
        '            yield AgentStatusEvent(status="compact_needed")',
        "",
        "    def _build_trace_url(self, session_id: str) -> str | None:",
        '        """Build Langfuse trace URL if context is available."""',
        "        if not self._langfuse_context:",
        "            return None",
        "        from src.configuration.config import get_settings",
        "",
        "        settings = get_settings()",
        "        if not (settings.langfuse_enabled and settings.langfuse_host):",
        "            return None",
        '        trace_id = self._langfuse_context.get("conversation_id", session_id)',
        '        return f"{settings.langfuse_host}/trace/{trace_id}"',
        "",
    ]

    # Replace lines[start_idx:end_idx] with replacement
    new_lines = lines[:start_idx] + replacement + lines[end_idx:]

    with open(PROCESSOR_PATH, "w") as f:
        f.write("\n".join(new_lines))

    print(f"Replaced lines {start_idx + 1}-{end_idx} with {len(replacement)} lines")
    print("Done!")


if __name__ == "__main__":
    main()
